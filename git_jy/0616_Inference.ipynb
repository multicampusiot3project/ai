{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c3de41",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d30ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c81cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e643018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':50,\n",
    "    'PATIENCE':10,\n",
    "    'class':14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb70e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_path = '/home/lab17/jupyter_home/Data/product_image/Training/'\n",
    "Valid_path = '/home/lab17/jupyter_home/Data/product_image/Validation/'\n",
    "Test_path = '/home/lab17/jupyter_home/git/test_img/'\n",
    "save_graph_path = './result/'\n",
    "save_model_path = '/home/lab17/jupyter_home/saved_models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c340a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca14fa",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caabde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data_dir):\n",
    "#     img_path_list = []\n",
    "    label_list = []\n",
    "    label_name_list = []\n",
    "    \n",
    "    image_path = os.path.join(data_dir, 'dessert')\n",
    "    \n",
    "    for product_name in os.listdir(image_path):\n",
    "        product_path = os.path.join(image_path, product_name)\n",
    "        if os.path.isdir(product_path):\n",
    "#             get image path\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_path_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "            label = list(product_name[:5])\n",
    "            name = product_name[6:]\n",
    "            \n",
    "            # get label\n",
    "            label_list.append(''.join(label))\n",
    "            label_name_list.append(name)\n",
    "                \n",
    "#     return img_path_list, label_list\n",
    "    return label_list, label_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b750e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list, label_name_list = get_train_data(Train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7fc35cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--targets\n",
      " [12 10  2  8  0  3 11  9  4  7 13  5  6  1]\n",
      "{'55701': 12, '45661': 10, '35211': 2, '45659': 8, '25222': 0, '35584': 3, '55034': 11, '45660': 9, '35585': 4, '45658': 7, '55702': 13, '45030': 5, '45657': 6, '25228': 1}\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(label_list)\n",
    "print('--targets\\n' , targets)\n",
    "\n",
    "label_encoder = {key:val for key, val in zip(label_list, targets)}\n",
    "print(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8bdf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "label_name_decoder = {key : value for key, value in zip(label_list, label_name_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f7ecf",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0584b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_data(data_dir):\n",
    "    img_valid_list = []\n",
    "    label_valid_list = []\n",
    "    \n",
    "    image_path = os.path.join(data_dir, 'dessert')\n",
    "    \n",
    "    for product_name in os.listdir(image_path):\n",
    "        product_path = os.path.join(image_path, product_name)\n",
    "        if os.path.isdir(product_path):\n",
    "            # get image path\n",
    "            img_valid_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "            img_valid_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "            label = list(product_name[:5])\n",
    "            \n",
    "            # get label\n",
    "            label_valid_list.append(''.join(label))\n",
    "                \n",
    "    return img_valid_list, label_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c37a8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_data_blanced(img, label):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(CFG['class']):\n",
    "        _img = img[(i * 15): ((i + 1) * 15)]\n",
    "        _label = label[i]\n",
    "        \n",
    "        for img_product in _img:\n",
    "            x.append(img_product)\n",
    "            y.append(_label)\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72826760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_valid_list, label_valid_list = get_valid_data(Valid_path)\n",
    "x_valid, y_valid = valid_data_blanced(img_valid_list, label_valid_list)\n",
    "len(label_valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4795154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([210, 14])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le2 = preprocessing.LabelEncoder()\n",
    "targets_y = le2.fit_transform(y_valid)\n",
    "targets_y_t = torch.as_tensor(targets_y)\n",
    "one_hot_valid_y = F.one_hot(targets_y_t)\n",
    "one_hot_valid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ad3ff",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f87f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    image_path = data_dir\n",
    "    \n",
    "#     for product in os.listdir(image_path):\n",
    "\n",
    "    # get image path\n",
    "    img_path_list.extend(glob(os.path.join(image_path, '*.jpg')))\n",
    "    img_path_list.extend(glob(os.path.join(image_path, '*.png')))\n",
    "    label_list = [ip[len('/home/lab17/jupyter_home/git/test_img/'):-6] for ip in img_path_list]\n",
    "\n",
    "    # get label\n",
    "#     label_list.append(''.join(label))\n",
    "                \n",
    "    return img_path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15f3cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path, test_label_list = get_test_data(Test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6076d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_x = test_img_path\n",
    "# 레이블을 one-hot-vector로 변환\n",
    "test_y = [label_encoder[key] for key in test_label_list]\n",
    "test_targets = torch.as_tensor(test_y)\n",
    "one_hot_test_y = F.one_hot(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9280e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55034, 11', '45661, 10', '25228, 1', '25222, 0', '45659, 8', '55701, 12', '45030, 5', '35211, 2', '45660, 9', '45659, 8', '35585, 4', '55702, 13', '25222, 0', '55702, 13', '35211, 2', '45030, 5', '45661, 10', '35584, 3', '25222, 0', '55701, 12', '35211, 2', '35211, 2', '55701, 12', '35584, 3', '45660, 9', '55702, 13', '25222, 0', '45657, 6', '45657, 6', '55701, 12', '45657, 6']\n"
     ]
    }
   ],
   "source": [
    "print([f'{i}, {y}' for i, y in zip(test_label_list, test_y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fd5d0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6b00271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsCustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # By default OpenCV uses BGR color space for color images,\n",
    "        # so we need to convert the image to RGB color space.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.train_mode:\n",
    "#             image = image.astype(np.int16)\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "A_test_transform = albumentations.Compose([\n",
    "                                    A.Resize(256, 256),\n",
    "                                    A.Normalize(mean=(0.744859, 0.735139, 0.711357), std=(0.100712, 0.120692, 0.167998)),  \n",
    "#                                     A.pytorch.transforms.ToTensor(),\n",
    "                                    A.pytorch.transforms.ToTensorV2(transpose_mask=True),\n",
    "                                ])\n",
    "\n",
    "A_vali_dataset = AlbumentationsCustomDataset(x_valid, one_hot_valid_y, train_mode=True, transforms=A_test_transform)\n",
    "A_vali_loader = DataLoader(A_vali_dataset, batch_size = 5, shuffle=False, num_workers=0, collate_fn=None)\n",
    "\n",
    "A_test_dataset = AlbumentationsCustomDataset(test_x, one_hot_test_y, train_mode=False, transforms=A_test_transform)\n",
    "A_test_loader = DataLoader(A_test_dataset, batch_size = 4, shuffle=False, num_workers=0, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dddfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(2048, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000,CFG['class'])\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # x = x.mean(dim=(-2, -1))\n",
    "        # (batch, 2048, 4, 4)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "#         out = self.softmax(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf06d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = accuracy_score(real, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5009cd",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300f3c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614aacd5c9ba4743bbf5bdf4e05c1e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss : 0.0018194397395875836\n",
      "val acc : 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b101b3b0e95d43c4a9a8525458c203fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 1.6851365715265274\n",
      "test acc : 0.41935483870967744\n"
     ]
    }
   ],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 34\n",
    "\n",
    "#---------\n",
    "model_name = 'ResNet50'\n",
    "model_lr = '0.0001'\n",
    "model_optim = 'adam'\n",
    "model_sch = 'CosineAnnealing' \n",
    "#---------\n",
    "\n",
    "model_test = ResNet50().to(device)\n",
    "# model_path = '/home/lab17/jupyter_home/saved_models/{}_{}_{}_{}_example.pth'.format(model_name, model_lr, model_optim, model_sch)\n",
    "# model_test.load_state_dict(torch.load(model_path))\n",
    "# model_test.load_state_dict(torch.load('/home/lab17/jupyter_home/saved_models/{}_{}_{}_{}_example.pth'.format(model_name, model_lr, model_optim, model_sch))['state_dict'])\n",
    "model_test.load_state_dict(torch.load('/home/lab17/jupyter_home/saved_models/{}_{}_{}_{}_example.pth'.format(model_name, model_lr, model_optim, model_sch)))\n",
    "model_test.eval()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "test_loss = []\n",
    "f_pred = []\n",
    "\n",
    "for img, label in tqdm(iter(A_vali_loader)):\n",
    "    img, label = img.float().to(device), label.float().to(device)\n",
    "    \n",
    "    # Data -> Model -> Output\n",
    "    logit = model_test(img)\n",
    "    logit = torch.squeeze(logit)\n",
    "    \n",
    "    # Calc loss\n",
    "    loss = criterion(logit, label)\n",
    "\n",
    "    test_loss.append(loss.item())\n",
    "    f_pred.extend(logit.argmax(1).detach().cpu().numpy().tolist())\n",
    "    \n",
    "print('val loss :' ,np.mean(test_loss))\n",
    "print('val acc :', score_function(targets_y, f_pred))\n",
    "\n",
    "test_loss = []\n",
    "f_pred = []\n",
    "\n",
    "for img, label in tqdm(iter(A_test_loader)):\n",
    "    img, label = img.float().to(device), label.float().to(device)\n",
    "    \n",
    "    # Data -> Model -> Output\n",
    "    logit = model_test(img)\n",
    "    logit = torch.squeeze(logit)\n",
    "    \n",
    "    # Calc loss\n",
    "    loss = criterion(logit, label)\n",
    "\n",
    "    test_loss.append(loss.item())\n",
    "    f_pred.extend(logit.argmax(1).detach().cpu().numpy().tolist())\n",
    "    \n",
    "print('test loss :' ,np.mean(test_loss))\n",
    "print('test acc :', score_function(test_y, f_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b0a83",
   "metadata": {},
   "source": [
    "- patience 너무커서 과적합,?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e81827",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_result = [label_name_decoder[label_decoder[result]] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6861970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test이미지 번호 | 정답 | 예측\n",
      "x 55034_1, 돌트로피칼666G, 돌황도666G\n",
      "o 45661_1, 씨제이)쁘티첼(요거젤리블루베리), 씨제이)쁘티첼(요거젤리블루베리)\n",
      "x 25228_1, 대만)파인애플케익184G, 대만)망고케익184g\n",
      "x 25222_3, 대만)망고케익184g, 돌황도666G\n",
      "x 45659_2, 씨제이)쁘티첼(요거젤리딸기), 돌황도666G\n",
      "o 55701_3, 쁘띠첼요거젤리밀감, 쁘띠첼요거젤리밀감\n",
      "o 45030_2, 돌황도666G, 돌황도666G\n",
      "x 35211_2, 매일유업)데르뜨130G, 돌황도666G\n",
      "x 45660_2, 씨제이)쁘티첼(요거젤리화이트코코), 씨제이)쁘티첼(요거젤리밀감)\n",
      "x 45659_1, 씨제이)쁘티첼(요거젤리딸기), 대만)망고케익184g\n",
      "o 35585_1, 매일데르뜨감귤90G, 매일데르뜨감귤90G\n",
      "x 55702_2, 쁘띠첼요거젤리복숭아, 씨제이)쁘티첼(요거젤리복숭아)\n",
      "x 25222_1, 대만)망고케익184g, 돌황도666G\n",
      "x 55702_3, 쁘띠첼요거젤리복숭아, 씨제이)쁘티첼(요거젤리복숭아)\n",
      "x 35211_1, 매일유업)데르뜨130G, 돌황도666G\n",
      "o 45030_1, 돌황도666G, 돌황도666G\n",
      "x 45661_2, 씨제이)쁘티첼(요거젤리블루베리), 돌황도666G\n",
      "x 35584_2, 매일데르뜨파인애플90G, 돌황도666G\n",
      "x 25222_4, 대만)망고케익184g, 돌황도666G\n",
      "x 55701_2, 쁘띠첼요거젤리밀감, 씨제이)쁘티첼(요거젤리밀감)\n",
      "x 35211_4, 매일유업)데르뜨130G, 씨제이)쁘티첼(요거젤리딸기)\n",
      "o 35211_3, 매일유업)데르뜨130G, 매일유업)데르뜨130G\n",
      "o 55701_1, 쁘띠첼요거젤리밀감, 쁘띠첼요거젤리밀감\n",
      "o 35584_1, 매일데르뜨파인애플90G, 매일데르뜨파인애플90G\n",
      "o 45660_1, 씨제이)쁘티첼(요거젤리화이트코코), 씨제이)쁘티첼(요거젤리화이트코코)\n",
      "x 55702_1, 쁘띠첼요거젤리복숭아, 씨제이)쁘티첼(요거젤리복숭아)\n",
      "o 25222_2, 대만)망고케익184g, 대만)망고케익184g\n",
      "o 45657_1, 씨제이)쁘티첼(요거젤리복숭아), 씨제이)쁘티첼(요거젤리복숭아)\n",
      "x 45657_3, 씨제이)쁘티첼(요거젤리복숭아), 돌황도666G\n",
      "o 55701_4, 쁘띠첼요거젤리밀감, 쁘띠첼요거젤리밀감\n",
      "o 45657_2, 씨제이)쁘티첼(요거젤리복숭아), 씨제이)쁘티첼(요거젤리복숭아)\n"
     ]
    }
   ],
   "source": [
    "print('test이미지 번호 | 정답 | 예측')\n",
    "for img, res in zip(test_img_path, f_result):\n",
    "    if label_name_decoder[img[-11:-6]]==res:\n",
    "        print(f'o {img[-11:-4]}, {label_name_decoder[img[-11:-6]]}, {res}')\n",
    "    else:\n",
    "        print(f'x {img[-11:-4]}, {label_name_decoder[img[-11:-6]]}, {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6275372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pred = []\n",
    "# pred_prob = []\n",
    "\n",
    "# image_data = Image.open('home/lab17/jupyter_home/Data/product_test/img.jpg')\n",
    "\n",
    "# image_transform = transforms.Compose([\n",
    "#     transforms.Resize(size=256),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.744859, 0.735139, 0.711357],\n",
    "#                          std=[0.100712, 0.120692, 0.167998])\n",
    "# ])\n",
    "\n",
    "# x = image_transform(image_data)\n",
    "# pred = model_test(x)\n",
    "# pred_prob.extend(pred.detach().cpu().numpy())\n",
    "# f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())\n",
    "\n",
    "# label_decoder = {val:key for key, val in zip(range(CFG['class']), sorted(label_list))}\n",
    "\n",
    "# f_result = [label_decoder[result] for result in f_pred]\n",
    "\n",
    "# print(f_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_17] *",
   "language": "python",
   "name": "conda-env-pytorch_17-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
